{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook can transform T2w sagittal nii.gz files into CT files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![DOI](https://zenodo.org/badge/605981537.svg)](https://zenodo.org/badge/latestdoi/605981537)\n",
    "\n",
    "We provide our weight for DDIM image under 'logs_diffusion3D/Diffusion_3D_T2w_CT_spine_sag/version_0/T2_to_CT_iso_diffusion_img.pt' in the archived version https://zenodo.org/record/8221159 or under this mirror: [Drive-link](https://studentpartnersde-my.sharepoint.com/:f:/g/personal/robert_graf_studentpartners_de/El5c-wZ7TXZJjpo8snSNAAsBpyiAlM4vzaBO5dr3y79fAw?e=O3Xaq3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil, floor\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import yaml\n",
    "from torch import Tensor\n",
    "from TPTBox import NII\n",
    "\n",
    "import utils.arguments as arguments\n",
    "from pl_models.diffusion.diffusion import Diffusion\n",
    "\n",
    "model_path = \"logs_diffusion3D/Diffusion_3D_T2w_CT_spine_sag/version_0/T2_to_CT_iso_diffusion_img.pt\"\n",
    "\n",
    "with open(str(model_path).replace(\".pt\", \".yaml\")) as file:\n",
    "    opt = arguments.Diffusion_Option()\n",
    "    opt.__dict__ = yaml.full_load(file)\n",
    "    opt.conditional_label_size = 0\n",
    "    opt.conditional_dimensions = 4\n",
    "    in_channel = opt.in_channel  # type: ignore\n",
    "diffusion = Diffusion(opt, channel=in_channel)\n",
    "dic = torch.load(model_path)\n",
    "diffusion.load_state_dict(dic, strict=True)\n",
    "\n",
    "mri_path = \"data/spine/sub-111168222_sequ-402_part-inphase_dixon.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import run_model, padded_shape\n",
    "\n",
    "\n",
    "def prepare_nii(mri_path):\n",
    "    nii = NII.load(mri_path, False, 0)\n",
    "    nii_iso = nii.rescale((1, 1, 1), verbose=True).reorient((\"R\", \"I\", \"P\"))\n",
    "    nii_iso /= nii_iso.max()\n",
    "    nii_iso.clamp_(min=0)\n",
    "    nii_iso = nii_iso * 2 - 1\n",
    "    target_shape = padded_shape(nii_iso.shape)\n",
    "    nii_iso = nii_iso.pad_to(target_shape)\n",
    "\n",
    "    arr = Tensor(nii_iso.get_array().astype(float))\n",
    "    # arr, padding = pad_size3D(arr)\n",
    "    return arr, 0, nii, nii_iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(mri_path, save=True, use_cpu=False):\n",
    "    arr, padding, nii, nii_iso = prepare_nii(mri_path)\n",
    "    if torch.cuda.is_available() and not use_cpu:\n",
    "        # If you run out of memory use max_shape= (arr.shape[-1]*arr.shape[-2]*arr.shape[-3])//2\n",
    "        ct_arr = run_model(diffusion, conditional=arr, gpu=True, eta=1, w=0, steps=25, depth=0)\n",
    "    else:\n",
    "        print(\"!!! Fall back to less steps on CPU instead of 25 GPU. !!!\")\n",
    "        ct_arr = run_model(diffusion, conditional=arr, gpu=False, eta=1, w=0, steps=5, depth=0)\n",
    "    ct_nii_iso = nii_iso.set_array(ct_arr.numpy())\n",
    "    ct_nii: NII = ct_nii_iso.set_dtype_(\"smallest_int\").resample_from_to(nii)\n",
    "    # revert_iso_to_original(ct_nii_iso, nii, padding)\n",
    "    if \"_\" in mri_path:\n",
    "        ct_path = mri_path.rsplit(\"_\", maxsplit=1)[0] + \"_desc-translated_ct.nii.gz\"\n",
    "        ct_pathi = mri_path.rsplit(\"_\", maxsplit=1)[0] + \"_desc-translated-iso_ct.nii.gz\"\n",
    "    else:\n",
    "        ct_path = mri_path.rsplit(\".\", maxsplit=2)[0] + \"_desc-translated_ct.nii.gz\"\n",
    "        ct_pathi = mri_path.rsplit(\".\", maxsplit=1)[0] + \"_desc-translated-iso_ct.nii.gz\"\n",
    "    if save:\n",
    "        ct_nii.set_dtype_(\"smallest_int\").save(ct_path)\n",
    "        ct_nii_iso.set_dtype_(\"smallest_int\").save(ct_pathi)\n",
    "    return ct_nii, ct_nii_iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_path = \"data/spine/sub-111168222_sequ-402_part-inphase_dixon.nii.gz\"\n",
    "ct_nii, ct_nii_iso = translate(mri_path, save=True, use_cpu=False)\n",
    "\n",
    "print(ct_nii)\n",
    "print(ct_nii_iso)\n",
    "print(\"You can now open the nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_path = \"data/spine/sub-111168222_sequ-401_part-inphase_dixon.nii.gz\"\n",
    "translate(mri_path, save=True)\n",
    "mri_path = \"data/spine/sub-111168222_sequ-403_part-inphase_dixon.nii.gz\"\n",
    "translate(mri_path, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
